test ssh
https://github.com/mscdex/ssh2#connection-hopping

maybe make the load config functions more generic.
should be a way to load a file, set defaults (deep), validate? and return an obj.

config
- provide an object OR a function.

thinking about changing the name from apps to config and from config to variables.


maybe we use a pull strategy for linking dependencies.
rather than organizing static assets, decorators middleware static ...,
in a defined way, sacrificing peolples ability to scale at the cost of disorganization,
we let people include shit in those top level dirs anyway they want, and we distribute them
based on the way they are included in resources and the main and shutdown files?


middleware, decorators, static, ..., should prob hav subfolders for each app - but not cuz what if u wanted /static/aa and other folders in root

presets and plugins (ok name, could be better)
- presets are collections of plugins
- plugins integrate into various aspects of brahma (multiple mounting points)
- thinking of a {
  cron: require('brahma-plugin-cron')
}

where would u put all ur mongorules config.
where would u put ssh credentials, api keys, passwords for shit
- in config, maybe make it convention for plugins to put config in config w/ a prefix maybe? dont love it, name conflicts

Services
 - mwb a1 file (how would this work)
 - i like the idea of giving people freedom in creating their folder structure. big apps gotta do weird shit sometimes.

People are going to do auth for sites, we want a modular way of using that same implemention across projects.

When planning the client architecture, make sure chnages are fast.
so if you change the name of your api server, make sure u dont need to update a million other things.
add this to some architectural goals list in the readme.

neo-architecture (readme and example project)
neo-core (a bunch of functions)
neo (meant to be cloned like rruhe)

neo status
neo update (resources, tests, dependencies, assets, config, apps, )
neo start
neo stop
* mention in docs that other implementations can have more methods but this is what it needs.

what does a neo project look like. the local boilerplate looks much different than the
codebase on the server. locally u have resources, ..., but u dont have that on remote.

since we are doing the live update thing...
we are required to update dependencies (files of code) and static assets (more files)
so we are going to be writing to disk
so the architecture needs to support this...


how to update node_modules while live
- could update pack.j -> run npm i -> clear require cache;
- big problem. npm is super unreliable and debugging its logs on remote systems sucks.
- so let's ship dependencies from our local to prod...
  - post deploy file checksum - do a recursive grep of remote files and compare concatenated file strings and also add up the file size.
  - post deploy run tests on the remote machine
- ./neo
  - ./dependencies
    - ./@todo
      - ./node_modules
      - ./static
  - ./lib
  - ./bin
- will need to set NODE_PATH='yourdir'/node_modules
- will still need to clear the require cache

we are forgetting database shit.

versioning
- what if we do semver, starting at 0.1.0 and each  update auto incremented the version
and by passing flags --updateMajor --updateMinor you could do the obvious
- where is the version stored

there are just resources
at the core of this you begin and end in resources
resources do depend on some other things
but everything eventually integrates w/ resources
resources directly integrate w/ systems:
  - services (libraries, email, sms, 3rd party apis, utility code, ...)
  - decorators
  - middleware
  - databases
  - static assets
  - caches. both local and remote.
  - other resources. both local and remote.
  - dynamic (env) config
  - static config
  - logging
  - cron
  - realtime
a decorator is a function
and this function can have dependencies
decorators need to ship w/ their resources to remote computers
so does middleware
middleware works very similar to decorators
so do services but they are more often collections of files
decorators and middleware are usually single files
but they can be collections of files all w/ depenendcies
all this needs to ship to remote systems.
require() is used to include dependencies
import is used too. often interchangeably.
the api is similar but the differences are greater when you get more low-level im sure
import isnt really standard yet (2017)
services are often contrib on npm and github
an example of a service is `axios`
services are used by everything...resources, decorators, middleware, other services
where as decorators are used only by resources
middleware is used only by resources

how to transport and load decorators/middleware/plugins/services.
- managing dependencies is your first issue.
  - how do u handle a contrib decorator requiring some npm module.
  - we need to ship the required code

architecture
- renaming a server (how does it affect the rest of your code - does the updating suck?)
  - would be awesome if we could identify the dependencies either though static analysis or otherwise
  - think what else do u rename and how to help w/ that.
updating ur apps file, e.g. you enable cors, we need a way to download koa-cors when in watch mode

\n EOL


status
- should regex all resources (and perhaps other stuff too) and make sure no one is using require or import statements
in their code.

middleware
- for http use w/ koa
- resource middleware is a decorator

there should be a way of organizing various types of middleware. the same goes for
decorators, services, and ...

decorators
- provide good documentation here. use autolog as an example to demonstrate the gotchyas.
- mention that their super powerful and they are the easiest way to fuck shit up.

how do u write a resource that loads and sends a static asset like a jpg.

think of how to manage the ecosystem of contribtued shit.
- how to keep track of it all.
- naming conventions (document in readme and elseware)
- brahma-plugin-NAME
- brahma-

see if we can make a generic neo interface for message services
might have to be baked in

@todo how u gonna do app init() and shutdown() funcs.

in ./config
- make sure people can replace an apps.js file w/ an ./config/apps/index.js

---

actions

helpers
- @todo latestDependencies - updates pack.j w/ latest versions of packages.
- plugin ecosystem, people can integrate help tasks.

serve
- @todo
- /endpoint to return brahma.config.js, env, status, ...?, (ssh only)

build
- the async implementation is a hack. needs to make sure all files are written before resolving main promise.
  - *making the bulk of file copying async is the main time saver. u dont really save any time making writeFileSync async.

deploy
- maybe there is separate `deploy` and `update` functionality. deploy deploys server boilerplate that u dont update. update is how u update that boilerplate.
- ideally you just run deploy, you see the manifest (whhats going to happen), you agree, and then shit happens.
  - deploy everything or select items?
    - big con w/ deploying items is you can fuck up. e.g. if u deploy a version of the config that is out of date w/ live code.
    - but sometimes u have edited your resources locally, but that shit aint ready for prod and all u wanna do is update your config e.g. change the name of something.
    - could mitigate this if ur resources requested config as its own prop, so we know what config items our prod code needs.
- ci server? see "breaking from convention - ci server"
- for selecting items to deploy: do one of those yeoman style option list things where you select what u wanna deploy (config, env,)

watch
- @todo

testing
- @todo for resources/middleware/decorators/services and other shit? see if i can implement some of my new testing style
- i want to use mocha and chai. i could integrate this so that these tools can be replaced by the user. will prob just use as defaults but in future versions.
- write your tests...last?
  - generate tests feature. generates tests for resources, ...,. if test does not yet exist.
  - list empty tests - you can keep calling generate tests as you continue to develope, eventually your will forget about some. this helps you get back to them.
  - remove tests for shit that doesnt exist (y/N prompt)
- want ot be able to run all tests, one test, or match wildcard...so api.* all api tests
- WILL WANT A WAY TO RUN TESTS ON SERVER - should be called automatically on update.

scafold
- like integrations, scafolding tools can be plugins. brahma-plugin-scafold
- i want to scafold - resources, ...
- should the tool be used to remove shit as well? remove resources? maybe this will be contrib plugin shit. a remove resource plugin should be able to do validation and make sure the removal wont break shit.

status
- @todo status makes sure you dont have conflicting ports in env.
- no news is good news. returns nothing if shits good. document behavior in readme.

---

plugins
- just be sure someone can write a docker deploy plugin
- mounting points:
  - `helpers`
  - `new`
  - `deploy`
  - logger
  - ratelimiter
  - database
  - cron
  - docs
  - mail
  - static asset cdn
  - versioning?
  - static analysis
  - testing?
  - ...

documentation
- we want the ability for plugins to create their own site for documentation
or github repo at least.

dependency management
- builds (OK)
- updates (@todo) - update live app, update running dev server (would be nice if we didnt need to do a server restart)

versioning
- i have an idea, i want to keep all apps w/ the same version. idk why. gotta flush this out.

changelog
- deployment plugin?

deployment
- if deploying a single app to multiple boxes, deploy 2 1 box first, make sure shit works, then deploy the rest, or clone the boxes.

env
- env var validation. make sure no one is updating to invalid types (object).

package.json

process.env
- conventionally does strings only. not anymore. w/ js moves we can make it much more dynamic.

lifecycle states
- startup
- run
- shutdown

local and remote ssl
- how we gonna do this? a way to generate local ssl certs via command line command?

zmq
xreq/xres intelligent req/res. it think it knows where to route a reply.
listens and resonds to file io
i think u can use tcp for remote communcation and ipc for local communication.
doesnt seem to be a request/response pattern for the node module.
to do ack or replys, in the message field include a replyTo address,
and we can use either zmq or http to send a reply.

neo {
  main() {}
  http() {}
  cron() {}
  custom() {}
  docs: []
}
idea - neo can be an architecture and a GH repo that uses its architecture. not everything needs to be its own framework.

SSH commands
- `neo status` - logs ?


---

breaking from convention
- no dev dependencies - intented to make remote builds faster. we are not doing remote builds.
- one of the things we do w/ microservices is create github repos for each service and
sometimes set up hooks to deploy to webservers. lets find a way to not do this w/o tradeoffs...setting up
these private github repos is a bit of work,
- ci server - the server has a tests endpoint that runs our tests in a forked process, and communicates the results. why use another server - its just worse?
- process.env uses jsmoves and can be any jsmoves type.
- main.js > index.js

make sure...
- the apps should be able to start themselves given an brahma.app.js file and other configs.
dont compile too much. the idea is for redeployment we want to just upload the configs and resources.
- keep integrations modular. abstract out modules like mongorules and make the their own github repos e.g. brahma-mongorules?, brahma-...
- static assets w/ ID caching. make sure this is a technique people will be able to implement.
- should the app server be its own module? build it and see what it would take
- try to connect to servers using ssh and ur ssh key.

---

app

communication
- property on $ctx (proptype property)
- $ctx.handler
- $ctx.call('ygl.apartments.status.change', 'method') // if in resources obj call directly, else use rabbit rpc. if method is empty, calls 'handler'
- $ctx.get('ygl.apartments.status.change.config.field') // gets a field value.
- we should make sure decorators dont fuck w/ these methods so maybe we can attach them last?
set ctx to null inside objs?

resource validator
- makes sure you don't have a get property or a call prop or anything that we are using elseware

Resources have the following possible entry points:
- restful HTTP interface
- response to zmq task
- cron
* since we are wrapping the "handler" and triggering other functions, they should be able to declare the triggers. e.g. you may only want to trigger an action after handler was called from cron and not when it's accessed via http.

---

realtime
- handshake
  - client connects
  - server asks for JWT
  - server uses JWT to verify (via mamaba communication syntax)
  - server asks client for subscriptions
  - client sends subscriptions
  - server associates subscriptions list w/ socket client ID.
  - server listens for all events
    - for each event, get each users subs w/ filters, check to see if each user
    gets updated, and update
  - maybe we can integrate a restful interface to add montioring/control

---

brahma status
- brahma status (runs all brahma statuses)
- brahma status resources (validate resources objects)
- brahma status resource RESOURCE_NAME (tells u what other resources are dependencies)
- brahma status routes
- brahma status service SERVICE_NAME (tells u what resources are dependent)
- brahma status decorator
- brahma status middleware
- brahma status config
- brahma status dependencies APP_NAME lists all dependencies for a given app
- brahma status deploy (makes sure you have git repos defined for each server)
- makes sure all resources have a location entry in their brahma.config.js
- brahma stats ports  - make sure we are using unique ports.
- have a status to log dependencies for a remote server. log pack.json

---

// const resources = new ResourceCollection();
// resources.forEach
// resources.get()
// resources.get('resource.name')
// resources.add()
// resources.update()
// resources.remove()

--

/update
/update/dependencies
/update/resources

/update/config
/update/dbs/[dbName]/[add/remove/update/[custom]]
/update/decorators/[decoratorName]/[add/remove/update]
/update/docs?
/update/integrations?
/update/middleware/[name]/[add/remove/update]
/update/services
/update/utils
/update/brahmaConfig

/update/startup
/update/shutdown

---

long todos
- how would u write a front-end app like react or something? (not super important - maybe there should be a way to build a framework for shit like this that integrates w/ brahma!)
- youtube video
- tests
- read zmq codebase

I want to be able to list a dependency in a resource w/o needing to isntall it.
installation should happen automatically.
- 3 sources: local, github npm.
- push endpoint to remote.
  - reads dependencies
  - installs dependencies to node_modules
  - refetches dependencies by default
  - idea - might not need to use node_modules at all if u can do this locally to each endopoint
  - there shoudl be a naming collision check w/ dependencies. make sure we are not injecting another ygl object or something.
- i want to be able to use koa1.x and koa2.x in the same project.
